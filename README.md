# ğŸ¥ Emosentia: AI-Powered Video Emotion and Sentiment Analysis

**Emosentia** is an intelligent video analysis tool built with **Whisper**, **Transformers**, **MediaPipe**, **MoviePy**, and **Streamlit**. It provides a unified pipeline for:

- ğŸ™ï¸ **Live Captioning** using Whisper ASR
- ğŸ˜Š **Sentiment Analysis** using HuggingFace Transformers
- ğŸ˜ƒ **Facial Emotion Detection** using MediaPipe & FER
- ğŸ§  **Annotated Final Video** with overlays using MoviePy

![Home Page](./home.png)
---

## ğŸ”§ Features

âœ… **Speech-to-Text Transcription**  
Uses OpenAIâ€™s Whisper model to extract text captions from audio in video files.

âœ… **Sentiment Analysis**  
Performs segment-wise sentiment detection using `cardiffnlp/twitter-roberta-base-sentiment`.

âœ… **Facial Emotion Recognition**  
Detects faces and recognizes emotional expressions using MediaPipe and the FER library.

âœ… **Subtitle + Sentiment Overlay**  
Creates a final video overlaying captions at the bottom and sentiment labels at the top-left, along with emotion-labeled face boxes.

âœ… **Streamlit Web App**  
Simple user interface to upload videos and download final processed outputs.

---

## ğŸ› ï¸ Tech Stack

| Component         | Library/Model                                 |
|------------------|------------------------------------------------|
| Speech to Text    | `whisper` (OpenAI Whisper Medium Model)       |
| Sentiment Analysis| `transformers` + `cardiffnlp` RoBERTa         |
| Face Detection    | `mediapipe`                                   |
| Emotion Detection | `FER` with MTCNN                              |
| Video Processing  | `moviepy`, `opencv-python`, `ffmpeg`          |
| UI                | `streamlit`                                   |

![Result Page](./result.png)
---

## ğŸš€ How It Works

1. **Upload a video file (MP4, AVI, MOV)**.
2. **Whisper** transcribes the audio and segments it.
3. Each segment is passed to a **sentiment classifier**.
4. The video is scanned frame-by-frame to detect **faces and emotions**.
5. Using **MoviePy**, all insights are overlaid on the original video:
   - Captions (bottom)
   - Sentiments (top-left)
   - Face bounding boxes + detected emotions

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/emosentia.git
cd emosentia

# Install dependencies
pip install -r requirements.txt

# Additional setup
# For Whisper
pip install git+https://github.com/openai/whisper.git

# For FFmpeg (ensure it's in PATH)
# For ImageMagick (set path in MoviePy if on Windows)
````

---

## ğŸ“‚ Usage

```bash
streamlit run app.py
```

Then go to `http://localhost:8501` in your browser.

---

## ğŸ§ª Sample Output

* ğŸ¬ Final video with subtitles and emotion boxes
* ğŸ—‚ï¸ Generated `.vtt` file with timestamps, captions, and sentiment labels
* ğŸ“¥ Downloadable final processed video

---

## ğŸ“ Folder Structure

```
Video_Analysis/
â”œâ”€â”€ final.py                  # Streamlit frontend + main logic
â”œâ”€â”€ Captions.py             # Shows up only the captions of the video
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ /videos                 # Uploaded and processed videos
â””â”€â”€ README.md               # You are here
```

---

## ğŸ’¡ Future Enhancements

* Real-time webcam-based emotion tracking
* Multilingual transcription
* Scene change detection and tagging
* Deepfake/spoof face detection

---

## ğŸ¤– Credits

* [OpenAI Whisper](https://github.com/openai/whisper)
* [Hugging Face Transformers](https://huggingface.co/)
* [MediaPipe by Google](https://mediapipe.dev/)
* [FER Emotion Detector](https://github.com/justinshenk/fer)
* [MoviePy](https://zulko.github.io/moviepy/)
* [Streamlit](https://streamlit.io/)

---
